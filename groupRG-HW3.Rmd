---
title: "Stat 602 Homework 3"
author: "Kiegan Rice and Nate Garton"
date: "Due ??"
output: 
  pdf_document: 
    fig_caption: yes
header-includes: \usepackage{float, mathtools, accents}
---


\newcommand{\dbtilde}[1]{\accentset{\approx}{#1}}

```{r global_options, echo = F, include = FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r packages, echo = F, warning = F, message = F}
library(tidyverse)
library(gridExtra)
library(knitr)
library(cvTools)
library(class)
library(caret)
library(elasticnet)
library(earth)
library(pls)
library(reshape2)
library(kernlab)
library(randomForest)
library(ranger)
library(nnet)
library(rpart)
library(C50)
library(glmnet)
library(klaR)
library(Cubist)
library(xgboost)
library(caretEnsemble)
```

# Problem 9  

The results from the predictions specified can be seen in \autoref{wines-preds}. 
```{r, echo = F, warning = F, message = F, fig.cap = "\\label{wines-preds}Predictions from each of the prediction methods."}
wines <- read_delim("data/winequality-white.csv", delim = ";")

## below is code from HW2... need to change "cv" to "repeatedcv" method.


# k nearest neighbors
wineControl <- trainControl(method = "repeatedcv", number = 10, 
                            repeats = 5, search = "grid")

wine_knn <- caret::train(form = quality~., data = wines, 
                       method = "knn",
                       trControl = wineControl)

preds_knn <- predict(wine_knn, newdata = wines)


# elastic net
#wine_enet <- caret::train(form = quality~., data = wines, 
#                       method = "enet",
#                       trControl = wineControl)

#preds_enet <- predict(wine_enet, newdata = wines)

#saveRDS(preds_enet, "data/preds_enet.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_enet <- readRDS("data/preds_enet.rda")


# principal components regression
wine_pcr <- caret::train(form = quality~., data = wines, 
                       method = "pcr",
                       trControl = wineControl)

preds_pcr <- predict(wine_pcr, newdata = wines)
#saveRDS(preds_pcr, "data/preds_pcr.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_pcr <- readRDS("data/preds_pcr.rda")


# partial least squares 
#wine_pls <- caret::train(form = quality~., data = wines, 
#                       method = "pls", 
#                       trControl = wineControl)

#preds_pls <- predict(wine_pls, newdata = wines)
#saveRDS(preds_pls, "data/preds_pls.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_pls <- readRDS("data/preds_pls.rda")

# MARS
#wine_mars <- caret::train(form = quality~., data = wines, 
#                       method = "earth",
#                       trControl = wineControl)

#preds_mars <- predict(wine_mars, newdata = wines)
#saveRDS(preds_mars, "data/preds_mars.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_mars <- readRDS("data/preds_mars.rda")


# neural nets  
#wines$quality_norm <- (wines$quality - mean(wines$quality))/sd(wines$quality)
#wine_nnet <- caret::train(form = quality_norm~., data = data.frame(wines)[,-12], 
#                       method = "nnet", 
#                       trControl = wineControl)

#preds_nnet <- predict(wine_nnet, newdata = data.frame(wines)[,-12])
#preds_nnet <- (preds_nnet*sd(wines$quality)) + mean(wines$quality)
#saveRDS(preds_nnet, "data/preds_nnet.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_nnet <- readRDS("data/preds_nnet")

#wines <- wines[,-13]
# regression tree
#wine_rpart <- caret::train(form = quality~., data = data.frame(wines), 
#                       method = "rpart",
#                       trControl = wineControl, 
#                       tuneLength = 20)

#preds_rpart <- predict(wine_rpart, newdata = data.frame(wines))

#saveRDS(preds_rpart, "data/preds_rpart.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_rpart <- readRDS("data/preds_rpart.rda")

# random forest 
#wine_rf <- caret::train(form = quality~., data = data.frame(wines), 
#                       method = "rf", 
#                       trControl = wineControl, 
#                       tuneLength = 1)

#preds_rf <- predict(wine_rf, newdata = data.frame(wines))
#saveRDS(preds_rf, "data/preds_rf.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_rf <- readRDS("data/preds_rf.rda")

#wine_xgb <- caret::train(form = quality~., data = wines, 
#                       method = "xgbTree",
#                       trControl = wineControl, 
#                       tuneLength = 1)

#preds_xgb <- predict(wine_xgb, newdata = wines) 

#saveRDS(preds_xgb, "data/preds_xgb.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_xgb <- readRDS("data/preds_xgb.rda")

#wine_cubist <- caret::train(form = quality~., data = data.frame(wines), 
#                       method = "cubist",
#                       trControl = wineControl, 
#                       tuneLength = 1)

#preds_cubist <- predict(wine_cubist, newdata = data.frame(wines))
#saveRDS(preds_cubist, "data/preds_cubist.rda")

## This takes a long time to re-render, so I saved and re-read in the predictions to save computing whenever we render the document.
preds_cubist <- readRDS("data/preds_cubist.rda")

wine_preds <- data.frame(quality = wines$quality, knn = preds_knn, 
                         enet = preds_enet, pcr = preds_pcr,
                         pls = preds_pls, mars = preds_mars[,1], 
                         nnet = preds_nnet[,1], 
                         rpart = preds_rpart,
                         rf = preds_rf,
                         xgb = preds_xgb,
                         cubist = preds_cubist)
pairs(wine_preds)
```

# Problem 10  
Shown below is the matrix of the proportion of predictions that agree between any two methods. The row and column labeled "actual" corresponds to the true data label.  

```{r, eval = TRUE, echo = TRUE, results = 'asis', message=FALSE, warning=FALSE}
wine <- read.csv(file = "data/winequality-white.csv", sep = ";", check.names = TRUE)
y <- -1*(wine$quality <= 7) + 1*(wine$quality > 7)
wine$y <- as.factor(y)
train_wine <- wine[,-(ncol(wine) - 1)]

fitControl <- trainControl(method = "repeatedcv", 
                           number = 10, repeats = 5, search = "grid")
# 
# set.seed(1308)
mods <- c("knn", "nnet", "rpart","rf", 
          "xgbTree", "C5.0","glmnet", "stepLDA", 
          "svmLinear", "svmPoly", "svmRadial")
# preds <- list()
# fitmod <- list()
# for(i in 1:length(mods))
# {
#   fitmod[[i]] <- caret::train(y ~ ., data = train_wine, trControl = fitControl, method = mods[i])
# }
# names(fitmod) <- mods
# 
# saveRDS(fitmod, file = "hw3_10_models.rda")
fitmod <- readRDS(file = "hw3_10_models.rda")
preds <- extractPrediction(models = fitmod)
pred_y <- data.frame("obs" = train_wine$y, "pred" = train_wine$y, 
                     "model" = "actual", "dataType" = "Training", "object" = "none")

preds <- rbind(preds, pred_y)

pred_mat <- matrix(nrow = length(mods) + 1, ncol = length(mods) + 1)
mods[12] <- "actual"
for(i in 1:nrow(pred_mat))
{
  for(j in 1:nrow(pred_mat))
  {
    pred_mat[i,j] <- mean(preds[preds$model == mods[i],]$pred == preds[preds$model == mods[j],]$pred)
  }
}
colnames(pred_mat) <- mods
rownames(pred_mat) <- mods
knitr::kable(round(pred_mat[,-ncol(pred_mat)], digits = 3))
```

# Problem 11  
kiegan will do this problem

# Problem 12  
The predictors from the boosted tree, kNN, and C5.0 are all better than the worst predictors (which all had tied training error of 0.963), and seem to be the least correlated with one another. Therefore, we will include these three predictors in the generalized stacking model. The best cv error from the stacked model was $\approx 0.976$ and the best individual model had a best cv error of $\approx 0.974$. The two scores are very close, which is to be expected, as the correlation of the predictions between each of these models was still very high.

```{r, eval = TRUE, echo = TRUE, message=FALSE, warning=FALSE}
set.seed(1308)
train_wine$target <- train_wine$y
levels(train_wine$target) <- c("bad", "good") 
train_wine <- train_wine[,-(ncol(train_wine) - 1)]
# fitControl <- trainControl(method = "repeatedcv", 
#                            number = 10, repeats = 5, search = "grid", classProbs = TRUE)
# clist <- caretList(target ~ .,data = train_wine,
#                    trControl = fitControl,
#                    methodList = c("xgbTree", "C5.0", "knn"))
# saveRDS(clist, file = "hw3_12_mod_list.rda")

clist <- readRDS(file = "hw3_12_mod_list.rda")

cverror <- c(clist$xgbTree$results[108,]$Accuracy,
             clist$C5.0$results[9,]$Accuracy,
             clist$knn$results[1,]$Accuracy)
stackmod <- caretStack(all.models = clist, 
                       method = "rf",
                       metric = "Accuracy",
                       trControl = trainControl(
                         method = "cv",
                         number = 10, 
                         search = "grid"
                       ))

cverror <- c(cverror, stackmod$error[1,]$Accuracy)
names(cverror) <- c("xgbTree","C5.0","knn", "stack")
print(cverror)
```


